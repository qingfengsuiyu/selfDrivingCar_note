{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.layers.core import Dense, Activation, Flatten,Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "tf.python.control_flow_ops = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./small_traffic_set/small_train_traffic.p', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "X_train, y_train = data['features'], data['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoxiaoyi/miniconda3/lib/python3.5/site-packages/ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(32, 32, 3...)`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# Build the Fully Connected Neural Network in Keras Here\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32,3,3, input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# preprocess data\n",
    "X_normalized = np.array(X_train / 255.0 - 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoxiaoyi/miniconda3/lib/python3.5/site-packages/keras/models.py:874: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 20 samples\n",
      "Epoch 1/10\n",
      "80/80 [==============================] - 1s 8ms/step - loss: 0.4529 - acc: 0.8125 - val_loss: 0.3136 - val_acc: 0.8500\n",
      "Epoch 2/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.3889 - acc: 0.8125 - val_loss: 0.2102 - val_acc: 0.8500\n",
      "Epoch 3/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2928 - acc: 0.8375 - val_loss: 0.1780 - val_acc: 1.0000\n",
      "Epoch 4/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2641 - acc: 0.8750 - val_loss: 0.1788 - val_acc: 0.8500\n",
      "Epoch 5/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2318 - acc: 0.9000 - val_loss: 0.1669 - val_acc: 0.8500\n",
      "Epoch 6/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.2074 - acc: 0.9625 - val_loss: 0.1415 - val_acc: 0.8500\n",
      "Epoch 7/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1856 - acc: 0.9000 - val_loss: 0.1104 - val_acc: 1.0000\n",
      "Epoch 8/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1755 - acc: 0.9375 - val_loss: 0.0936 - val_acc: 1.0000\n",
      "Epoch 9/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1554 - acc: 0.9500 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 10/10\n",
      "80/80 [==============================] - 0s 2ms/step - loss: 0.1314 - acc: 0.9750 - val_loss: 0.0806 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 标签One_hot\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "label_binarizer = LabelBinarizer()\n",
    "y_one_hot = label_binarizer.fit_transform(y_train)\n",
    "\n",
    "model.compile('adam', 'categorical_crossentropy', ['accuracy'])\n",
    "history = model.fit(X_normalized, y_one_hot, nb_epoch=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n",
      "20/20 [==============================] - 0s 567us/step\n",
      "loss: 0.13407453894615173\n",
      "acc: 1.0\n"
     ]
    }
   ],
   "source": [
    "with open('./small_traffic_set/small_test_traffic.p', 'rb') as f:\n",
    "    data_test = pickle.load(f)\n",
    "\n",
    "X_test = data_test['features']\n",
    "y_test = data_test['labels']\n",
    "\n",
    "# preprocess data\n",
    "X_normalized_test = np.array(X_test / 255.0 - 0.5 )\n",
    "y_one_hot_test = label_binarizer.fit_transform(y_test)\n",
    "\n",
    "print(\"Testing\")\n",
    "\n",
    "metrics = model.evaluate(X_normalized_test, y_one_hot_test)\n",
    "for metric_i in range(len(model.metrics_names)):\n",
    "    metric_name = model.metrics_names[metric_i]\n",
    "    metric_value = metrics[metric_i]\n",
    "    print('{}: {}'.format(metric_name, metric_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
